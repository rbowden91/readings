Helpful readings on machine learning/neural networks:
* [Tensorflow Tutorials](https://www.tensorflow.org/get_started/)
* [Deeplearning4j Tutorials](https://deeplearning4j.org)
* [Michael Nielsen's book](http://neuralnetworksanddeeplearning.com/chap1.html)
* [Christopher Olah's blog](http://colah.github.io/)
* [Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [Quora post on differntiable neural computers](https://www.quora.com/How-does-the-Deepmind-DNC-Differentiable-Neural-Computer-compare-to-LSTMs-and-RNNs)
* [Google's Seq2seq](https://google.github.io/seq2seq)
* [An extended intro to LSTMs](https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html)
* [Volterra Kernels Quora post?](https://www.quora.com/Whats-trending-in-machine-learning-outside-of-deep-learning)

1. **[Building Program Vector Representations for Deep Learning](https://www.dropbox.com/s/hr98eduivh7d8kk/mou_building_program_vector.pdf)**  
Lili Mou, Ge Li, Yuxuan Liu, Hao Peng, Zhi Jin, Yan Xu, Lu Zhang  
Peking University  
ICSE 2014  
[My Notes](mou_building_program_vector.md)  

1. **[Convolutional Neural Networks over Tree Structures for Programming Language Processing](https://www.dropbox.com/s/acbailuttrjvyoa/mou_cnn_for_programs.pdf)**  
Lili Mou, Ge Li, Lu Zhang, Tao Wang, Zhi Jin  
Peking University, Stanford  
AAAI 2016  

1. **[Hybrid computing using a neural
network with dynamic external memory](https://www.dropbox.com/s/3iuaikk7pxfxwvo/graves_differentiable_neural_computer.pdf)**  
Graves et al.  
Google DeepMind  
Nature 2016  

1. **[Neural Turing Machines](https://www.dropbox.com/s/t0wi172qf8qqefl/graves_neural_turing_machine.pdf)**  
Graves, Wayne, Danihelka  
Google DeepMind  
2014  

1. **[Efficient Estimation of Word Representations in
Vector Space](https://www.dropbox.com/s/8atl3o492x9on9b/mikolov_word2vec.pdf)**  
Mikolov, Chen, Corrado, Dean  
Google  
2013  
[word2vec Explained](https://arxiv.org/pdf/1402.3722v1.pdf)
[Quora post on word2vec](https://www.quora.com/How-does-word2vec-work)

1. **[Learning Program Embeddings to Propagate Feedback on Student Code](https://www.dropbox.com/s/ecmvcxdu94ncojm/piech_learning_program_embeddings.pdf)**  
Piech, Huang, Nguyen, Phulsuksombati, Sahami, Guibas  
Stanford, Google  
ICML 2015  

